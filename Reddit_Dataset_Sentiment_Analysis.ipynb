{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WfHjbb_lYm6"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b_yUvzIlbia",
        "outputId": "3e9fb7e5-4bdf-40e8-9706-3711a729e547"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>label</th>\n",
              "      <th>preprocessed_posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>posting since one helped last time yesterday s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>hey everyone mobile pardon type happen id like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>alone feel isolated wife kiss parent shilling ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>mentalhealth reason take school year since one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>tired getting overlooked girl tired tell relat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>parent got fight today tried telling best frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>hi pad student hyderabad india pad research fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>hate fucking hate stare mirror see human emoti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>rousing much right time laugh say next fail es...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>depression</td>\n",
              "      <td>0</td>\n",
              "      <td>therapist told dont really know mean wait week...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    subreddit  label                                 preprocessed_posts\n",
              "0  depression      0  posting since one helped last time yesterday s...\n",
              "1  depression      0  hey everyone mobile pardon type happen id like...\n",
              "2  depression      0  alone feel isolated wife kiss parent shilling ...\n",
              "3  depression      0  mentalhealth reason take school year since one...\n",
              "4  depression      0  tired getting overlooked girl tired tell relat...\n",
              "5  depression      0  parent got fight today tried telling best frie...\n",
              "6  depression      0  hi pad student hyderabad india pad research fo...\n",
              "7  depression      0  hate fucking hate stare mirror see human emoti...\n",
              "8  depression      0  rousing much right time laugh say next fail es...\n",
              "9  depression      0  therapist told dont really know mean wait week..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the dataset\n",
        "df = pd.read_parquet(\"Big_preprocessed_filter_data.parquet\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l09puP5KlvpR",
        "outputId": "8298ca5a-f8e7-4ce7-c30a-0c6675079152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 3 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   subreddit           20000 non-null  object\n",
            " 1   label               20000 non-null  int64 \n",
            " 2   preprocessed_posts  20000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 468.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCaPstbkvKWD",
        "outputId": "8106e47a-f0bc-4ac2-9feb-7b8f120a3c22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data size: (16000, 3)\n",
            "Testing data size: (4000, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divide dataset into training and testing sets (80% training, 20% testing)\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data size: {train_data.shape}\")\n",
        "print(f\"Testing data size: {test_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvdXqmGqlacN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Prepare the TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Fit the vectorizer on training data and transform both training and test data\n",
        "X_train_tfidf = tfidf.fit_transform(train_data['preprocessed_posts'])\n",
        "X_test_tfidf = tfidf.transform(test_data['preprocessed_posts'])\n",
        "\n",
        "# Convert labels into numeric form\n",
        "y_train = train_data['subreddit']\n",
        "y_test = test_data['subreddit']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mASUUqH-r5cL",
        "outputId": "df33835c-d0b9-4721-9169-47ceeac5f01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.85375\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Anxiety       0.87      0.83      0.85      1981\n",
            "  depression       0.84      0.88      0.86      2019\n",
            "\n",
            "    accuracy                           0.85      4000\n",
            "   macro avg       0.85      0.85      0.85      4000\n",
            "weighted avg       0.85      0.85      0.85      4000\n",
            "\n",
            "Random Forest Accuracy: 0.85625\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Anxiety       0.87      0.83      0.85      1981\n",
            "  depression       0.84      0.88      0.86      2019\n",
            "\n",
            "    accuracy                           0.86      4000\n",
            "   macro avg       0.86      0.86      0.86      4000\n",
            "weighted avg       0.86      0.86      0.86      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Vectorizing the text data\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(train_data['preprocessed_posts']).toarray()\n",
        "X_test = vectorizer.transform(test_data['preprocessed_posts']).toarray()\n",
        "\n",
        "# SVM Model\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred, zero_division=1))\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIsv6Pj-7TcW",
        "outputId": "69a1d347-24e3-4287-a65f-634f83232e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.8500\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the training data and transform both training and test data\n",
        "y_train = le.fit_transform(train_data['subreddit'])\n",
        "y_test = le.transform(test_data['subreddit'])\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train_tfidf, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test_tfidf)\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAqdbjGyA2MS",
        "outputId": "67e0d216-7388-4ab4-9873-4523957a9fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Model  Accuracy  F1-Score\n",
            "          SVM   0.85375  0.853654\n",
            "Random Forest   0.85625  0.856160\n",
            "      XGBoost   0.85000  0.849702\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize results list\n",
        "results = []\n",
        "\n",
        "# Initialize the LabelEncoder (if not already done)\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Assuming 'Subreddit' is the target column with categories like 'Anxiety', 'depression'\n",
        "le.fit(train_data['subreddit'])  # Fit on training data to get all categories\n",
        "\n",
        "# 1. SVM Evaluation\n",
        "svm_pred_encoded = le.transform(svm_pred)  # Encode SVM predictions\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred_encoded)\n",
        "svm_f1 = f1_score(y_test, svm_pred_encoded, average='weighted')\n",
        "results.append({'Model': 'SVM', 'Accuracy': svm_accuracy, 'F1-Score': svm_f1})\n",
        "\n",
        "# 2. Random Forest Evaluation\n",
        "rf_pred_encoded = le.transform(rf_pred)  # Encode Random Forest predictions\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred_encoded)\n",
        "rf_f1 = f1_score(y_test, rf_pred_encoded, average='weighted')\n",
        "results.append({'Model': 'Random Forest', 'Accuracy': rf_accuracy, 'F1-Score': rf_f1})\n",
        "\n",
        "# 3. XGBoost Evaluation\n",
        "# XGBoost predictions are likely already numerical (since you used LabelEncoder for training)\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "xgb_f1 = f1_score(y_test, y_pred_xgb, average='weighted')\n",
        "results.append({'Model': 'XGBoost', 'Accuracy': xgb_accuracy, 'F1-Score': xgb_f1})\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}